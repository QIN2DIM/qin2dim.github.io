<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Claude2.0 on Echosec @QIN2DIM</title><link>https://blog.echosec.top/tags/claude2.0/</link><description>Recent content in Claude2.0 on Echosec @QIN2DIM</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Sun, 01 Oct 2023 12:17:13 +0800</lastBuildDate><atom:link href="https://blog.echosec.top/tags/claude2.0/index.xml" rel="self" type="application/rss+xml"/><item><title>Crazy Claude: Legends of the Nautical Age</title><link>https://blog.echosec.top/p/crazy-claude/</link><pubDate>Sun, 01 Oct 2023 12:17:13 +0800</pubDate><guid>https://blog.echosec.top/p/crazy-claude/</guid><description>&lt;img src="https://blog.echosec.top/p/crazy-claude/abrar-khan.jpg" alt="Featured image of post Crazy Claude: Legends of the Nautical Age" />&lt;h2 id="demo">Demo&lt;/h2>
&lt;div class="video-wrapper">
&lt;video
controls
src="https://r2-datalake.echosec.top/blog-obs/2023/10/5aa34a6e07c346af7bf4dd5a102c410e.mp4"
>
&lt;p>
Your browser doesn't support HTML5 video. Here is a
&lt;a href="https://r2-datalake.echosec.top/blog-obs/2023/10/5aa34a6e07c346af7bf4dd5a102c410e.mp4">link to the video&lt;/a> instead.
&lt;/p>
&lt;/video>
&lt;/div>
&lt;h2 id="颠覆之始">颠覆之始&lt;/h2>
&lt;p>2023.09.27，hCaptcha 更新了他们的基准服务，有一类新推送的人机挑战类型是选择「仅出现一次」或「不重复」的目标。&lt;/p>
&lt;p>大致情况如下图所示：&lt;/p>
&lt;p>&lt;img width="307" src="https://r2-datalake.echosec.top/blog-obs/2023/10/5baaf71126fce72c38079414377d1c70.png"> &lt;img width="307" src="https://r2-datalake.echosec.top/blog-obs/2023/10/797a833b00a1786df8daedfe1bbad375.png">&lt;/p>
&lt;p>在我看来，这是一个十分常规的实例分割任务，我第一时间想到了延续之前的工作流，使用基于深度学习的方法处理这类任务。但在观察 CI 推送的测试图片之后，我反而觉得“深度学习”的实现会非常复杂，而使用传统机器学习的方法可以做到像素级的识别，且响应速度更快。&lt;/p>
&lt;p>样例图片如下所示：&lt;/p>
&lt;p>&lt;img src="https://r2-datalake.echosec.top/blog-obs/2023/10/16ce7797f5813fd57da4fc5358261ffd.png"
loading="lazy"
>&lt;/p>
&lt;p>从样例中不难发现：要识别的目标都被裁成圆形子图。这是一个非常好的信号，机器学习的方法很适合处理这种特征明显的分割任务。&lt;/p>
&lt;p>很快，我们可以得到一个大致的行进流程：从生成图中识别出若干个圆形子图（也即前景/实例），使用一种方法去横比这些子图的特征，最后筛选出「与众不同」的实例。&lt;/p>
&lt;span id='back1'>
&lt;p>当然，这套流程有很明显的缺点，例如圆形子图边缘被羽化，背景出现大量的等半径的外接圆，子图蒙版变成多边形或三角形，这套流程都有可能出现很大的问题。但相比于加几十行代码就能实现的功能，要投入大量时间精力筛选数据集并训练模型的深度学习路线来说还是要方便不少。&lt;/p>
&lt;p>那么这篇博客的趣味性在哪呢？那便是我通过 Chat with LLM 的方式实现了这个解决方案。大致流程可看「&lt;a class="link" href="#screenshot" >聊天截图&lt;/a>」以及「&lt;a class="link" href="#links" >相关分支&lt;/a>」仅用80行代码就实现了一个查找「不重复目标」的需求。&lt;/p>
&lt;p>如果你已经大致瞄了一眼截图开头的部分，也许你会有所惊讶，LLM 给出的内容不再是大而空的屁话，也不再一本正经地列出一些相关但没用的信息，而是针对需求给出确切有效的解决方案。这是一个非常乐观的优化信号。显然，Claude 也仅仅是文本模态的语言模型，很好奇未来跨模态模型大规模使用之后，Captcha service 这个行业会和 LLM 碰撞出怎样的火花。&lt;/p>
&lt;h2 id="题外话">题外话&lt;/h2>
&lt;p>也许你用同样的 prompt 问 Bard，ChatGPT-35，文心或是星火，得到的答复可能还是比较糟糕的。至少从我的实践来看：&lt;/p>
&lt;ol>
&lt;li>
&lt;p>&lt;a class="link" href="https://chat.openai.com/chat" target="_blank" rel="noopener"
>ChatGPT 3.5&lt;/a>仍会给出「正确话」，一再调优之后仍然没法使用。因为 opencv-python 版本变动后 API 接口参数变动非常大，版本差了两年，拷贝来的代码大概率是没法直接用的。GPT4 我还没进行实际测试，但效果应与 Claude2.0 十分相近。&lt;/p>
&lt;p>2023年9月27日，&lt;a class="link" href="https://twitter.com/OpenAI/status/1707077710047216095" target="_blank" rel="noopener"
>OpenAI 宣布&lt;/a>「ChatGPT Plus和Enterprise(企业版)用户现在可以使用浏览功能,这项功能很快会扩展到所有用户。要启用该功能,请在 GPT-4下拉菜单中选择“使用必应浏览”(Browse with Bing)。」如果这一限制被突破，GPT-4 的各项能力又将一骑绝尘。&lt;/p>
&lt;p>2022年12月4日，我发表了第一篇&lt;a class="link" href="https://blog.echosec.top/p/chatgpt-register/" >关于 ChatGPT 的博文&lt;/a>，距今已近一年。这段时间的发展令人振奋，发生了许多颠覆性的变化，许多新的商业模式也正在萌芽。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://yiyan.baidu.com/" target="_blank" rel="noopener"
>文心&lt;/a>和&lt;a class="link" href="https://xinghuo.xfyun.cn/desk" target="_blank" rel="noopener"
>星火&lt;/a>的问题相对来说比较明显，它们似乎并不能理解我在说什么，我也从未感觉描述自己的想法如此费劲。显然，文心和星火都是将具备多种能力的基准模型缝到了一起，这没什么不好，只是在解决垂域问题时缺乏足够的深度。&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a class="link" href="https://bard.google.com/" target="_blank" rel="noopener"
>Bard&lt;/a> 是首个免费开玩且能图文交互的大模型产品，在 Bard 上我测试了分类任务，效果非常棒，但看起来检测和分割任务还不能直接触发。&lt;/p>
&lt;/li>
&lt;/ol>
&lt;span id='links'>
&lt;h2 id="相关链接">相关链接&lt;/h2>
&lt;p>&lt;a class="link" href="#back1" >← back&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/QIN2DIM/hcaptcha-challenger/issues/752" target="_blank" rel="noopener"
>⤴️ [*Challenge] default @ please click on the object that appears only once #752&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/QIN2DIM/hcaptcha-challenger/issues/756" target="_blank" rel="noopener"
>⤴️ [Challenge] default @ please click the center of the object that is never repeated #756&lt;/a>&lt;/p>
&lt;p>&lt;a class="link" href="https://github.com/QIN2DIM/hcaptcha-challenger/pull/764" target="_blank" rel="noopener"
>🔀 Feat(cv-component): 761 OpenCV toolkit #764&lt;/a>&lt;/p>
&lt;h2 id="用例演示">用例演示&lt;/h2>
&lt;div class="video-wrapper">
&lt;video
controls
src="https://r2-datalake.echosec.top/blog-obs/2023/10/43ff9132c02e95fbf0ea1ab4884bb3a6.webm"
>
&lt;p>
Your browser doesn't support HTML5 video. Here is a
&lt;a href="https://r2-datalake.echosec.top/blog-obs/2023/10/43ff9132c02e95fbf0ea1ab4884bb3a6.webm">link to the video&lt;/a> instead.
&lt;/p>
&lt;/video>
&lt;/div>
&lt;span id='screenshot'>
&lt;h2 id="聊天截图">聊天截图&lt;/h2>
&lt;p>&lt;a class="link" href="#back1" >← back&lt;/a>&lt;/p>
&lt;p>&lt;img src="https://r2-datalake.echosec.top/blog-obs/2023/10/fd24422f12fdaa51010babbb01b2bdc4.png"
loading="lazy"
alt="20230930-232302"
>&lt;/p></description></item></channel></rss>